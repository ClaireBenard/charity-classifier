---
title: "Charity commission data classification"
output: html_notebook
---

Aim of this notebook:
classifying charities based on their object.

Final product: maybe a shiny app that, given a charitable object returns the proability of each class?

# Set up

```{r libraries and paths}
library(tidyverse)
library(textrecipes)
library(tidymodels)

data_path <- paste0(here::here(), "/data/")

```

```{r load data}
charity_classification <- jsonlite::fromJSON(paste0(data_path, "publicextract.charity_classification.json"))

governing_doc <- jsonlite::fromJSON(paste0(data_path, "publicextract.charity_governing_document.json"))
```

# Clean data

This analysis focusses on service providers only. This means that we remove organisations that are only grant makers or advocacy organisations.

In theory, the problem is a multi-class multi-label classification problem, where each charity can have several of the 16 labels.
For the purpose of this product, I simplify the problem to make it only a multi-class problem: each charity can have one of the 16 labels.

```{r select relevant charities}
service_providers <- charity_classification %>%
  filter(classification_description == "Provides Services") 

classification_clean <- charity_classification %>%
  filter(organisation_number %in% service_providers$organisation_number, # keep only service providers
         classification_type == "What", # keep only sector
         classification_description != "General Charitable Purposes") %>% # removing uninformative type
  select(registered_charity_number, classification_description)

nb_classes <- classification_clean %>% 
  count(registered_charity_number)

classification_clean_one_class <- classification_clean %>% semi_join(nb_classes %>% filter(n == 1), by = "registered_charity_number")

```

```{r illustrate the problem}
classification_clean %>% 
  count(registered_charity_number) %>% 
  ggplot(aes(n)) + geom_histogram(stat = "count") +
  labs(title = "3 out of 4 charities tick more than one box",
       x = "Number of box ticked",
       y = "Count of charities")
```


```{r select relevant charitable objects}
clean_text <- . %>%
  tolower() %>%
  str_replace_all(., "[:punct:]", " ") %>%
  str_replace_all(., "\\s+", " ") %>%
  trimws()

charitable_objects <- governing_doc %>% select(registered_charity_number, charitable_objects) %>%
  mutate(charitable_objects = clean_text(charitable_objects)) %>%
  group_by(registered_charity_number, charitable_objects) %>%
  summarise_all(first) %>%
  ungroup() %>%
  group_by(registered_charity_number) %>%
  summarise(charitable_objects = paste(charitable_objects, collapse = " ")) %>%
  ungroup()

```

```{r link classification and object}
df <- classification_clean_one_class %>% inner_join(charitable_objects, by = 'registered_charity_number')
```

# Build models

## Pre-processing of text

```{r text processing}
prep_text_rec <-
  recipe(classification_description ~ charitable_objects + registered_charity_number, data = df) %>%
  # Do not use the charity number in the model
  update_role(registered_charity_number, new_role = "ID") %>%
  # Tokenise text
  step_tokenize(charitable_objects)  %>%
  # Remove stop words
  step_stopwords(charitable_objects) %>%
  # Stem text
  step_stem(charitable_objects) %>%
  # Only keep the most important words
  step_tokenfilter(charitable_objects, max_tokens = 500) %>%  
  # Transform each words by its tf_idf values
  step_tfidf(charitable_objects) %>% 
  # Normalise TFIDF values
  step_normalize(all_numeric())

```

## Train, Test and validation split

```{r split data}
set.seed(123)

data_split <- initial_split(df,
                            strata = classification_description,
                            prop = 0.6)

train_data <- training(data_split)
test_data  <- testing(data_split)

valid_data <- classification_clean %>% 
  semi_join(nb_classes %>% filter(n == 2), by = "registered_charity_number") %>%
  inner_join(charitable_objects, by = "registered_charity_number")
```

## Evaluating different models

```{r}
exec_wf <- function(this_model){
  wf <- workflow() %>%
  add_recipe(prep_text_rec) %>%
  add_model(this_model)

  print(paste(Sys.time(), "Starting the fit"))
  
  this_model_fit <- wf %>%
  fit(data = train_data)
  
  return(this_model_fit)
  
}

generate_model_results <- function(this_model){
  
  engine <- this_model$engine
  
  print(paste(Sys.time(), "Building and execute workflow for", engine))
  model_fit <- exec_wf(this_model)
  
  print(paste0("save model ", this_model))
  saveRDS(model_fit, paste0(here::here(), "/models", "/model_", engine, ".rds"))

  print(paste(Sys.time(), "Making predictions..."))
  predictions <- predict(model_fit, test_data) %>%
    bind_cols(test_data %>%
                select(registered_charity_number, classification_description) %>%
                mutate(model_name = engine))
  
  return(predictions)
}

```

```{r define models}
mnr <- multinom_reg() %>%
  set_engine("nnet", MaxNWts = 10000)

rf <- rand_forest(
  mode = "classification",
  engine = "ranger",
  mtry = NULL,
  trees = NULL,
  min_n = NULL
)

knn <- nearest_neighbor(
  mode = "classification",
  engine = "kknn",
  neighbors = 10,
  weight_func = NULL,
  dist_power = NULL
)

svm <- svm_poly(
  mode = "classification",
  engine = "kernlab",
  cost = NULL,
  degree = NULL,
  scale_factor = NULL,
  margin = NULL
)

```

```{r}
model_list <- list(mnr, rf, knn, svm)

eval_df <- model_list %>%
  map_dfr(generate_model_results)

```

!! ONLY RUN IF YOU ALREADY HAVE TRAINED MODELS !!
 ```{r, echo=FALSE}
# # load pre-trained models
# final_trained_models <- list()
# 
# for (i in seq(1:4)){
#   final_trained_models[[i]] <- readRDS(paste0(here::here(), "/models", "/model", i, ".rds"))
# }
# 
# # generate eval_df from pre_trained models
# generate_results_from_trained <- function(this_trained_model){
#   
#   engine <- this_trained_model$fit$fit$spec$engine
#   true_class <- test_data %>%
#     select(registered_charity_number, classification_description)
#   
#   print(paste0("starting predictions for ", engine, " at ", Sys.time()))
#   
#   predictions <- predict(this_trained_model, test_data) %>%
#     bind_cols(true_class) %>%
#     mutate(model_name = engine)
#   
#   print(paste0("Done with ", engine, " at ", Sys.time()))
#   
#   return(predictions)
# }
# 
# eval_df <- final_trained_models %>%
#   map_dfr(generate_results_from_trained)
 ```

```{r}
eval_df %>%
  group_by(model_name) %>%
  accuracy(as.factor(classification_description), .pred_class)
```

```{r}
eval_df %>%
  group_by(classification_description, model_name) %>%
  summarise(true_pred_prop = mean(classification_description == .pred_class)) %>%
  ggplot(aes(x = reorder(classification_description, true_pred_prop), 
             y = true_pred_prop)) + 
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 90)) +
  coord_flip() +
    facet_grid(. ~  model_name) +
  labs(title = "Proportion of true predictions",
       subtitle = "By charitable categories",
       x = NULL,
       y = NULL)
```

```{r}
eval_df %>% count(registered_charity_number, .pred_class)
```

```{r}
acc_per_cat <- eval_df %>%
  group_by(classification_description, model_name) %>%
  summarise(accuracy_per_cat = mean(classification_description == .pred_class)) %>%
  ungroup()
```

```{r}
write_csv(acc_per_cat, here::here("./data/accuracy_per_cat.csv"))
```

```{r}
vote <- . %>%
  inner_join(acc_per_cat, by = c('.pred_class' = 'classification_description',
                                 'model_name')) %>%
  group_by(registered_charity_number, .pred_class) %>% 
  mutate(votes = n()) %>%
  ungroup() %>%
  group_by(registered_charity_number) %>%
  slice_max(order_by = votes) %>%
  slice_max(order_by = accuracy_per_cat) %>%
  summarise_all(first) %>% # edge case when 2 models have the same accuracy
  ungroup()
  
  
voting <- eval_df %>% 
  vote()

```

```{r}
voting %>%
  group_by(classification_description) %>%
  summarise(true_pred_prop = mean(classification_description == .pred_class)) %>%
  ggplot(aes(x = reorder(classification_description, true_pred_prop), 
             y = true_pred_prop)) + 
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 90)) +
  coord_flip() +
  labs(title = "Proportion of true predictions",
       subtitle = "By charitable categories",
       x = NULL,
       y = NULL)

```

```{r build final voting wf}
final_trained_models <- list("kernlab" = NULL, 
                             "kknn" = NULL,
                             "nnet" = NULL,
                             "ranger" = NULL)

for (i in c("kernlab", "kknn", "nnet", "ranger")){
  print(paste0("Loading /model_", i, ".rds at ", Sys.time()))
  final_trained_models[[i]] <- readRDS(paste0(here::here(), "/models/model_", i, ".rds"))
}


predict_wf <- function(this_model, data_to_predict){
  
  engine <- this_model$fit$actions$model$spec$engine
  
  predict(this_model, data_to_predict) %>%
    bind_cols(data_to_predict %>%
                select(registered_charity_number) %>%
                mutate(model_name = engine))
}

voting_wf <- function(data_to_predict){
  
  x <- data_to_predict
  list_to_predict <- list(x, x, x, x) # hacky way to create a DF of DFs

    final_trained_models %>%
    map2_dfr(., list_to_predict, predict_wf) %>%
    vote()
    
} 

results <- voting_wf(valid_data)

```

```{r}
eval_validation <- results %>% 
  inner_join(valid_data, by = c("registered_charity_number")) %>%
  mutate(true_pred = .pred_class == classification_description) %>% 
  group_by(registered_charity_number) %>%
  summarise(true_pred = sum(true_pred) > 0) %>%
  ungroup()

eval_validation %>% 
  summarise(accuracy = mean(true_pred))
```

# Testing on fake charity
```{r}
results %>% filter(registered_charity_number == 200490)

voting_wf(data.frame(registered_charity_number = 1234,
                     charitable_objects = "to promote the relief of physically disabled people in the county of surrey in such ways as the association shall from time to time determine and in particular by enabling those people to live more independently providing advice information and education providing and supporting opportunities for respite and social activities"))
```

